{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HumzaW245/iCAD-Dental/blob/main/iCAD_Dental_Coding_Test_Colab_MultiClass.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djaAjDFIQ0K3"
      },
      "source": [
        "# Downloading data using kaggle API\n",
        "\n",
        "Read comment by 'Nikhil Ojha' for simple instructions on how to do download dataset (https://www.kaggle.com/discussions/general/74235)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "uZDeetCrLF-A"
      },
      "outputs": [],
      "source": [
        "! pip install -q kaggle\n",
        "from google.colab import files\n",
        "files.upload() #Upload kaggle.json (it contains API key to access kaggle datasets)\n",
        "\n",
        "\n",
        "\n",
        "from IPython.display import clear_output\n",
        "clear_output() #To clear output printed since previous lines will show kaggle API key information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "ORn2TnysN73K"
      },
      "outputs": [],
      "source": [
        "!rm -r ~/.kaggle\n",
        "!mkdir ~/.kaggle\n",
        "!mv ./kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "FSLV2-pq76Ix"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "7QsVnjvVOWev"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1BBnZrhOYi9",
        "outputId": "c5a95e9c-feb2-4ded-92b9-4b2b6a96bfc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "isic-2019-skin-lesion-images-for-classification.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ],
      "source": [
        "# To download dataset, go to dataset ->https://www.kaggle.com/datasets/salviohexia/isic-2019-skin-lesion-images-for-classification/discussion\n",
        "# Then click 3 dots menu -> 'Copy API Command'\n",
        "# since in google colab, need to do ! first -> ! <pastedAPIcommandHere>\n",
        "\n",
        "! kaggle datasets download -d salviohexia/isic-2019-skin-lesion-images-for-classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "zHHKrQPkPzHy"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile('isic-2019-skin-lesion-images-for-classification.zip', 'r')\n",
        "zip_ref.extractall('/content/ISIC2019')\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAJ-yg7nR5nj",
        "outputId": "7f6ad295-0ba5-4280-b7a2-1dc03de751fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              image Class  Class_Index\n",
            "0      ISIC_0000000    NV            1\n",
            "1      ISIC_0000001    NV            1\n",
            "3      ISIC_0000003    NV            1\n",
            "5      ISIC_0000006    NV            1\n",
            "6      ISIC_0000007    NV            1\n",
            "...             ...   ...          ...\n",
            "12407  ISIC_0033810    DF            5\n",
            "12444  ISIC_0033847    DF            5\n",
            "12457  ISIC_0033860    DF            5\n",
            "12488  ISIC_0033891    DF            5\n",
            "12732  ISIC_0034135    DF            5\n",
            "\n",
            "[12658 rows x 3 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-655cf82f2897>:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  reduced_df = reduced_df.append(class_subset)\n",
            "<ipython-input-24-655cf82f2897>:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  reduced_df = reduced_df.append(class_subset)\n",
            "<ipython-input-24-655cf82f2897>:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  reduced_df = reduced_df.append(class_subset)\n",
            "<ipython-input-24-655cf82f2897>:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  reduced_df = reduced_df.append(class_subset)\n",
            "<ipython-input-24-655cf82f2897>:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  reduced_df = reduced_df.append(class_subset)\n",
            "<ipython-input-24-655cf82f2897>:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  reduced_df = reduced_df.append(class_subset)\n",
            "<ipython-input-24-655cf82f2897>:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  reduced_df = reduced_df.append(class_subset)\n",
            "<ipython-input-24-655cf82f2897>:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  reduced_df = reduced_df.append(class_subset)\n"
          ]
        }
      ],
      "source": [
        "# ctrl-f 'In [13]' if want details of making a complete dataset using the metadata too -> https://www.kaggle.com/code/shonenkov/merge-external-data/notebook\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Specify the path to the CSV files\n",
        "metadata_csv_file_path = '/content/ISIC2019/ISIC_2019_Training_Metadata.csv'\n",
        "data_csv_file_path = '/content/ISIC2019/ISIC_2019_Training_GroundTruth.csv'\n",
        "\n",
        "\n",
        "\n",
        "# Load the metadata and main data from the CSV file\n",
        "metadata_df = pd.read_csv(metadata_csv_file_path)\n",
        "main_df = pd.read_csv(data_csv_file_path)\n",
        "\n",
        "\n",
        "#Getting class name and index column (index is used to make predictions more easily)\n",
        "main_df['Class'] = main_df.apply(lambda row: main_df.columns[(row == 1)].tolist()[0], axis=1)\n",
        "\n",
        "\n",
        "def reduce_data_50pct(df):\n",
        "\n",
        "  class_counts = df['Class'].value_counts()\n",
        "  #print(class_counts)\n",
        "  target_size = class_counts // 2  # Half of the original size for each class\n",
        "  #print(target_size)\n",
        "  reduced_df = pd.DataFrame(columns=df.columns)\n",
        "\n",
        "  for class_label, size in target_size.items():\n",
        "      class_subset = df[df['Class'] == class_label].head(size)\n",
        "      reduced_df = reduced_df.append(class_subset)\n",
        "  return reduced_df\n",
        "\n",
        "main_df = reduce_data_50pct(main_df)\n",
        "#print(f\"NEW VALUE COUNTS: {main_df['Class'].value_counts()}\")\n",
        "\n",
        "\n",
        "\n",
        "class_idx_map = {'MEL':0, 'NV':1, 'BCC':2, 'AK':3, 'BKL':4, 'DF':5, 'VASC':6, 'SCC':7, 'UNK':8}\n",
        "main_df['Class_Index'] = main_df['Class'].apply(lambda class_name: class_idx_map[class_name])\n",
        "\n",
        "main_df = main_df[['image','Class', 'Class_Index']]\n",
        "\n",
        "print(main_df.head(-5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "KV-D2uwjgsGw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "ml4MA_rITYAR"
      },
      "outputs": [],
      "source": [
        "dataset_dir = '/content/ISIC2019/'\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "# Define a custom dataset class\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, root_dir, dataframe, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.dataframe = dataframe\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        label = self.dataframe.iloc[idx]['Class_Index']\n",
        "        class_name = self.dataframe.iloc[idx]['Class']\n",
        "        #Get label index to tensor\n",
        "        label = torch.tensor(label)\n",
        "\n",
        "        #Get image\n",
        "        img_id = self.dataframe.iloc[idx, 0]\n",
        "        img_path = os.path.join(self.root_dir, class_name + '/' + img_id + '.jpg')  # Assuming images are in JPEG format\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        #Apply transformations to image\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfY6nyO9BWFd"
      },
      "source": [
        "# DataLoaders and Transformations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "E_avZmV-gQew"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data frame into training and test sets\n",
        "train_df, test_df = train_test_split(main_df, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# Transformations to use for preprocessing (Arbitrarily chose these to have standardized data)\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Resize the image to a common size\n",
        "    transforms.ToTensor(),  # Convert PIL Image to PyTorch tensor\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize using ImageNet statistics\n",
        "])\n",
        "\n",
        "train_data = CustomDataset(dataset_dir, train_df, transform = data_transforms)\n",
        "test_data = CustomDataset(dataset_dir, test_df, transform = data_transforms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "-yb_xjogMNn2"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XiXBBLwpCUVv"
      },
      "source": [
        "# Train and Test functions for how training will be done"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "CXOjTv4kUSG4"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score\n",
        "\n",
        "def train(model, device, train_loader, optimizer, epoch, display=True):\n",
        "    #Set model to training mode ----------------------------------CARE WHEN NORMALIZATION, DIFFERENT FOR TRAIN/TEST---------------------\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "\n",
        "        #Data to device\n",
        "        data, target = data.to(device), target.to(device)\n",
        "\n",
        "        #Reset grad for next batch\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "\n",
        "        #Loss\n",
        "        loss = F.cross_entropy(output, target)\n",
        "\n",
        "        #Backprop\n",
        "        loss.backward()\n",
        "\n",
        "        #Optimization step (Parameter Update)\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "    #Log results of each epoch. CARE: Epoch will be an integer passed so the parameter is ONLY for tracking here. train(...) needs to be called in a loop based on how many epochs are to be trained (each epoch's index passed as epoch)\n",
        "    if display:\n",
        "      print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "          epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "          100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    #Set model to test mode ----------------------------------CARE WHEN NORMALIZATION, DIFFERENT FOR TRAIN/TEST---------------------\n",
        "    model.eval()\n",
        "\n",
        "    true_labels = []  # To collect true labels\n",
        "    predicted_labels = []  # To collect predicted labels\n",
        "\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    #no_grad() will not hold grad, which is fine since we do not want to calculate gradient as we are only interested in checking the prediction from the forward pass.\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "\n",
        "            #Test Loss\n",
        "            test_loss += F.cross_entropy(output, target, size_average=False).item() # sum up batch loss\n",
        "\n",
        "            #Predicted class\n",
        "            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "\n",
        "            #Number of correct predictions in the batch to update overall total of correct predictions\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "            # Collect true and predicted labels\n",
        "            true_labels.extend(target.cpu().numpy())\n",
        "            predicted_labels.extend(pred.cpu().numpy())\n",
        "\n",
        "    #Average test loss over all dataset\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    #Log results\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "\n",
        "    # Calculate confusion matrix\n",
        "    conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
        "    print('Confusion Matrix:')\n",
        "    print(conf_matrix)\n",
        "\n",
        "\n",
        "    #----------CANNOT DO specificity and sensitivity for binary classification using tn, fp, fn, tp------------\n",
        "    # tn, fp, fn, tp = conf_matrix.ravel()\n",
        "\n",
        "    # # Calculate sensitivity\n",
        "    # # Sensitivity = TP / (TN + FP)\n",
        "    # sensitivity = tp / (tn + fp)\n",
        "    # print(f'Sensitivity: {sensitivity:.2f}')\n",
        "\n",
        "    # # Calculate specificity\n",
        "    # # Specificity = TN / (TN + FP)\n",
        "    # specificity = tn / (tn + fp)\n",
        "    # print(f'Specificity: {specificity:.2f}')\n",
        "\n",
        "    return accuracy, true_labels, predicted_labels\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyoKo78yE3xd"
      },
      "source": [
        "# Define the Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "pzASGzm4MlPM"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torchvision.models as models\n",
        "\n",
        "class Net(torch.nn.Module):\n",
        "    '''\n",
        "    Constructor. Define all layers (These were chosen through trying different variations by starting with 2-3 convolution layers and adding batchNorm and pooling between them as needed, with different parameters)\n",
        "    '''\n",
        "    def __init__(self, finetune_backbones):\n",
        "        super(Net, self).__init__()\n",
        "        self.model =  models.resnet50(pretrained=True)\n",
        "\n",
        "        # FT backbone (before output layers. freeze/unfreeze)\n",
        "        self.finetune_backbones = finetune_backbones\n",
        "        for i, param in enumerate(self.model.parameters()):\n",
        "          param.requires_grad = self.finetune_backbones\n",
        "\n",
        "\n",
        "        #New output head for the target task\n",
        "        in_features = self.model.fc.in_features #The fc layer of resenet50 is Linear(in_features=2048, out_features=1000, bias=True) so storing the 2048 and replacing this to map from 2048 to numClasses for target task ====can see the fc layer like this: backbone = models.resnet50(pretrained=True) => print(backbone.fc)\n",
        "        targetTaskOutFeatures = 9 # num of classes in target task\n",
        "        classifier = nn.Linear(in_features, targetTaskOutFeatures, bias=True)  # Create a new classifier\n",
        "        classifier.weight.requires_grad = True\n",
        "        classifier.bias.requires_grad = True\n",
        "        self.model.fc = classifier  # Replace the classifier layer\n",
        "\n",
        "        # self.layers = nn.ModuleList()\n",
        "\n",
        "        # # 3 Channels in (RGB at the start is what image channels are) and 16 channels out (arbitrarily chose 16)\n",
        "        # self.layers+=[nn.Conv2d(3, 16,  kernel_size=3) ,\n",
        "        #               nn.ReLU(inplace=True)]\n",
        "\n",
        "        # # Batch norm layer to normalize the tensor produced from convolution so covariances are not too high and this can help avoid issues like oscillating loss\n",
        "        # self.layers+=[nn.BatchNorm2d(16)]\n",
        "\n",
        "        # # Pooling to reduce number of params to learn so training time is improved by reducing dimension (e.g. image size) as it passes through the Net\n",
        "        # # basically as if multiple pixels would share the same parameter so 1 gradient is calculated between multiple pixels to allow training without needing higher number of computations (less gradients to calculate)\n",
        "        # self.layers+=[nn.MaxPool2d(kernel_size= 2, stride=2, padding= 0)]\n",
        "\n",
        "        # self.layers+=[nn.Conv2d(16, 32,  kernel_size=3),\n",
        "        #               nn.ReLU(inplace=True)]\n",
        "\n",
        "        # self.layers+=[nn.MaxPool2d(kernel_size= 2, stride=2, padding= 0)]\n",
        "\n",
        "        # self.layers+=[nn.Conv2d(32, 32,  kernel_size=3),\n",
        "        #               nn.ReLU(inplace=True)]\n",
        "\n",
        "        # self.layers+=[nn.MaxPool2d(kernel_size= 2, stride=2, padding= 0)]\n",
        "\n",
        "\n",
        "        # '''\n",
        "        # Linear layers after flattening\n",
        "        # # '''\n",
        "        # self.fc1 = nn.Linear(32*26*26, 64) #NEED TO MODIFY first argument to output of previous layers' size product of each observation. THIS BASED ON LAST INPUT SIZE (Changes as we do convolutions, pooling, etc)\n",
        "        # self.layer_norm1 = nn.LayerNorm(64)\n",
        "        # self.fc2 = nn.Linear(64, 30)\n",
        "        # self.layer_norm2 = nn.LayerNorm(30)\n",
        "        # self.fc3 = nn.Linear(30, 9) # Linear layer from X neurons to Y where y is number of classes being predicted\n",
        "    '''\n",
        "    Forward Pass\n",
        "    '''\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.model(x)\n",
        "        return x\n",
        "        # for i in range(len(self.layers)):\n",
        "        #   #print(f'Input size before layer: {self.layers[i]} --- size: {x.shape}')\n",
        "        #   x = self.layers[i](x)\n",
        "\n",
        "        #print(f'Input size before flattening convolution layers result -> {x.shape}')\n",
        "        # outChannelsHeightWidthproduct = x.shape[1]*x.shape[2]*x.shape[3]\n",
        "        # x = x.view(-1, outChannelsHeightWidthproduct)\n",
        "\n",
        "\n",
        "        # x = nn.functional.relu(self.fc1(x))\n",
        "\n",
        "\n",
        "        # x = self.layer_norm1(x)\n",
        "        # x = nn.functional.relu(self.fc2(x))\n",
        "        # x = self.layer_norm2(x)\n",
        "        # x = self.fc3(x)\n",
        "        #print(f'Final input size -> {x.shape}')\n",
        "        #return x\n",
        "\n",
        "\n",
        "    '''\n",
        "    Turn finetuning of the backbone layers on or off.\n",
        "    '''\n",
        "    def FTBackbone(backbone, boolVal):\n",
        "      for i, param in enumerate(backbone.parameters()):\n",
        "        param.requires_grad = boolVal\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTqusmWBE7_X"
      },
      "source": [
        "# Execute training and testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "naD0uVMUCF4e"
      },
      "outputs": [],
      "source": [
        "def evaluate(train_data, val_data, epochs, b_size, lr, momentum, weight_decay, optimizer_name, finetune_backbones):\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    '''\n",
        "    Send to dataloader\n",
        "    '''\n",
        "    #Make use of dataloader so we can easily work with it later on.\n",
        "    train_loader = torch.utils.data.DataLoader(train_data,\n",
        "                                              batch_size=b_size,\n",
        "                                              shuffle=True,\n",
        "                                              drop_last = True)\n",
        "\n",
        "    val_loader = torch.utils.data.DataLoader(val_data,\n",
        "                                            batch_size=b_size,\n",
        "                                            shuffle=False,\n",
        "                                            drop_last = True)\n",
        "\n",
        "\n",
        "    '''\n",
        "    Initialize model, send to device and set optimizer\n",
        "    '''\n",
        "    model = Net(finetune_backbones).to(device)\n",
        "\n",
        "    #Optimizer\n",
        "    if optimizer_name == \"SGD\":\n",
        "      print(f'USING OPTIMIZER -------- SGD')\n",
        "      optimizer = torch.optim.SGD(model.parameters(),lr=lr, momentum= momentum, weight_decay= weight_decay)\n",
        "    else:\n",
        "      print(f'USING OPTIMIZER -------- ADAM')\n",
        "      optimizer = torch.optim.Adam(model.parameters(),lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "\n",
        "\n",
        "    '''\n",
        "    Train model for certain epochs\n",
        "    '''\n",
        "    for epoch in range(epochs):\n",
        "      train(model, device, train_loader, optimizer, epoch, display= True)# epoch%5==0)\n",
        "\n",
        "    '''\n",
        "    Test model and results (will run for each seed and store result so all seed accuracies can be aggregated)\n",
        "    '''\n",
        "    accuracy, true_labels, predicted_labels = test(model, device, val_loader)\n",
        "\n",
        "    #Average accuracies over all random state seeds\n",
        "    print('='*30)\n",
        "    print(f'Hyperparameters used were: \\n epochs, b_size, lr, momentum, weight_decay\\n {epochs}, {b_size}, {lr}, {momentum}, {weight_decay}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "EJvxpTSQ0SfC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af0a9ca0-0f71-45bd-d307-b52d16cf515e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "USING OPTIMIZER -------- ADAM\n",
            "Train Epoch: 0 [9984/10130 (99%)]\tLoss: 0.639523\n",
            "Train Epoch: 1 [9984/10130 (99%)]\tLoss: 0.484891\n",
            "Train Epoch: 2 [9984/10130 (99%)]\tLoss: 0.249745\n",
            "Train Epoch: 3 [9984/10130 (99%)]\tLoss: 0.057958\n",
            "Train Epoch: 4 [9984/10130 (99%)]\tLoss: 0.027860\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.7027, Accuracy: 1964/2533 (77.54%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 280   99   17    7   14    3    3    8]\n",
            " [  54 1156    7    1   34    3    0    0]\n",
            " [   4    7  267   13    7    0    0   15]\n",
            " [   5    0   19   31    3    1    0   11]\n",
            " [  22   59    6    1  157    3    0    5]\n",
            " [   2    1    1    0    0   16    0    1]\n",
            " [   1    1    1    0    0    0   22    0]\n",
            " [   7    1   13    1    4    3    0   35]]\n",
            "==============================\n",
            "Hyperparameters used were: \n",
            " epochs, b_size, lr, momentum, weight_decay\n",
            " 5, 128, 0.0001, 0, 0.0005\n"
          ]
        }
      ],
      "source": [
        "epochs = 5\n",
        "b_size = 128\n",
        "lr = 0.0001\n",
        "momentum = 0\n",
        "weight_decay = 0.0005\n",
        "optimizer_name = 'Adam'\n",
        "finetune_backbones = True\n",
        "\n",
        "model = evaluate(train_data, test_data, epochs, b_size, lr, momentum, weight_decay, optimizer_name, finetune_backbones)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "4bQxeevo4SXu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69613c63-5fd6-464c-eb67-6f7708ac6b20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We can see in the confusion matrix along the diagonal are the correct predictions and other values are the incorrectly predicted class counts for each class.      e.g.row2,col2 has 1156 correct predictions for that class, 54 incorrectly predicted as class for col 1, etc\n"
          ]
        }
      ],
      "source": [
        "print(\"We can see in the confusion matrix along the diagonal are the correct predictions and other values are the incorrectly predicted class counts for each class.\\\n",
        "      e.g.row2,col2 has 1156 correct predictions for that class, 54 incorrectly predicted as class for col 1, etc\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vTkqJBC77E-s"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "authorship_tag": "ABX9TyMYyR49P5kYCif8VCnQ21j2",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}