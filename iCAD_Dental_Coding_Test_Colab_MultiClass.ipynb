{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HumzaW245/iCAD-Dental/blob/main/iCAD_Dental_Coding_Test_Colab_MultiClass.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djaAjDFIQ0K3"
      },
      "source": [
        "# Downloading data using kaggle API\n",
        "\n",
        "Read comment by 'Nikhil Ojha' for simple instructions on how to do download dataset (https://www.kaggle.com/discussions/general/74235)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uZDeetCrLF-A"
      },
      "outputs": [],
      "source": [
        "! pip install -q kaggle\n",
        "from google.colab import files\n",
        "files.upload() #Upload kaggle.json (it contains API key to access kaggle datasets)\n",
        "\n",
        "\n",
        "\n",
        "from IPython.display import clear_output\n",
        "clear_output() #To clear output printed since previous lines will show kaggle API key information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORn2TnysN73K",
        "outputId": "a4ab755a-add3-4349-fa5f-e75f20a92e6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '/root/.kaggle': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!rm -r ~/.kaggle\n",
        "!mkdir ~/.kaggle\n",
        "!mv ./kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FSLV2-pq76Ix"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7QsVnjvVOWev"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1BBnZrhOYi9",
        "outputId": "5dc6585d-359b-4da2-b5dc-32e7faf3ee97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading isic-2019-skin-lesion-images-for-classification.zip to /content\n",
            "100% 9.09G/9.10G [05:36<00:00, 32.7MB/s]\n",
            "100% 9.10G/9.10G [05:36<00:00, 29.0MB/s]\n"
          ]
        }
      ],
      "source": [
        "# To download dataset, go to dataset ->https://www.kaggle.com/datasets/salviohexia/isic-2019-skin-lesion-images-for-classification/discussion\n",
        "# Then click 3 dots menu -> 'Copy API Command'\n",
        "# since in google colab, need to do ! first -> ! <pastedAPIcommandHere>\n",
        "\n",
        "! kaggle datasets download -d salviohexia/isic-2019-skin-lesion-images-for-classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "zHHKrQPkPzHy"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile('isic-2019-skin-lesion-images-for-classification.zip', 'r')\n",
        "zip_ref.extractall('/content/ISIC2019')\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAJ-yg7nR5nj",
        "outputId": "fd1f341c-3c44-4fdb-e0e4-3293ff9ef173"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              image  MEL   NV  BCC   AK  BKL   DF  VASC  SCC  UNK Class  \\\n",
            "0      ISIC_0000000  0.0  1.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0    NV   \n",
            "1      ISIC_0000001  0.0  1.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0    NV   \n",
            "2      ISIC_0000002  1.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0   MEL   \n",
            "3      ISIC_0000003  0.0  1.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0    NV   \n",
            "4      ISIC_0000004  1.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0   MEL   \n",
            "...             ...  ...  ...  ...  ...  ...  ...   ...  ...  ...   ...   \n",
            "25321  ISIC_0073240  0.0  1.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0    NV   \n",
            "25322  ISIC_0073241  1.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0   MEL   \n",
            "25323  ISIC_0073244  0.0  1.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0    NV   \n",
            "25324  ISIC_0073245  0.0  1.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0    NV   \n",
            "25325  ISIC_0073246  0.0  0.0  1.0  0.0  0.0  0.0   0.0  0.0  0.0   BCC   \n",
            "\n",
            "       Class_Index  \n",
            "0                1  \n",
            "1                1  \n",
            "2                0  \n",
            "3                1  \n",
            "4                0  \n",
            "...            ...  \n",
            "25321            1  \n",
            "25322            0  \n",
            "25323            1  \n",
            "25324            1  \n",
            "25325            2  \n",
            "\n",
            "[25326 rows x 12 columns]\n"
          ]
        }
      ],
      "source": [
        "# ctrl-f 'In [13]' if want details of making a complete dataset using the metadata too -> https://www.kaggle.com/code/shonenkov/merge-external-data/notebook\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Specify the path to the CSV files\n",
        "metadata_csv_file_path = '/content/ISIC2019/ISIC_2019_Training_Metadata.csv'\n",
        "data_csv_file_path = '/content/ISIC2019/ISIC_2019_Training_GroundTruth.csv'\n",
        "\n",
        "\n",
        "\n",
        "# Load the metadata and main data from the CSV file\n",
        "metadata_df = pd.read_csv(metadata_csv_file_path)\n",
        "main_df = pd.read_csv(data_csv_file_path)\n",
        "\n",
        "\n",
        "#Getting class name and index column (index is used to make predictions more easily)\n",
        "main_df['Class'] = main_df.apply(lambda row: main_df.columns[(row == 1)].tolist()[0], axis=1)\n",
        "\n",
        "\n",
        "def reduce_data_50pct(df):\n",
        "\n",
        "  class_counts = df['Class'].value_counts()\n",
        "  #print(class_counts)\n",
        "  target_size = class_counts // 2  # Half of the original size for each class\n",
        "  #print(target_size)\n",
        "  reduced_df = pd.DataFrame(columns=df.columns)\n",
        "\n",
        "  for class_label, size in target_size.items():\n",
        "      class_subset = df[df['Class'] == class_label].head(size)\n",
        "      reduced_df = reduced_df.append(class_subset)\n",
        "  return reduced_df\n",
        "\n",
        "main_df = reduce_data_50pct(main_df)\n",
        "#print(f\"NEW VALUE COUNTS: {main_df['Class'].value_counts()}\")\n",
        "\n",
        "\n",
        "\n",
        "class_idx_map = {'MEL':0, 'NV':1, 'BCC':2, 'AK':3, 'BKL':4, 'DF':5, 'VASC':6, 'SCC':7, 'UNK':8}\n",
        "main_df['Class_Index'] = main_df['Class'].apply(lambda class_name: class_idx_map[class_name])\n",
        "\n",
        "main_df = main_df[['image','Class', 'Class_Index']]\n",
        "\n",
        "print(main_df.head(-5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "KV-D2uwjgsGw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ml4MA_rITYAR"
      },
      "outputs": [],
      "source": [
        "dataset_dir = '/content/ISIC2019/'\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "# Define a custom dataset class\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, root_dir, dataframe, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.dataframe = dataframe\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        label = self.dataframe.iloc[idx]['Class_Index']\n",
        "        class_name = self.dataframe.iloc[idx]['Class']\n",
        "        #Get label index to tensor\n",
        "        label = torch.tensor(label)\n",
        "\n",
        "        #Get image\n",
        "        img_id = self.dataframe.iloc[idx, 0]\n",
        "        img_path = os.path.join(self.root_dir, class_name + '/' + img_id + '.jpg')  # Assuming images are in JPEG format\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        #Apply transformations to image\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfY6nyO9BWFd"
      },
      "source": [
        "# DataLoaders and Transformations *************CHECK TRANSF THAT SHOULD BE APPLIED...maybe some standard one"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "E_avZmV-gQew"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data frame into training and test sets\n",
        "train_df, test_df = train_test_split(main_df, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# Transformations to use for preprocessing (Arbitrarily chose these to have standardized data)\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Resize the image to a common size\n",
        "    transforms.ToTensor(),  # Convert PIL Image to PyTorch tensor\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize using ImageNet statistics\n",
        "])\n",
        "\n",
        "train_data = CustomDataset(dataset_dir, train_df, transform = data_transforms)\n",
        "test_data = CustomDataset(dataset_dir, test_df, transform = data_transforms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "-yb_xjogMNn2"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XiXBBLwpCUVv"
      },
      "source": [
        "# Train and Test functions for how training will be done"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "CXOjTv4kUSG4"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "def train(model, device, train_loader, optimizer, epoch, display=True):\n",
        "    #Set model to training mode ----------------------------------CARE WHEN NORMALIZATION, DIFFERENT FOR TRAIN/TEST---------------------\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "\n",
        "        #Data to device\n",
        "        data, target = data.to(device), target.to(device)\n",
        "\n",
        "        #Reset grad for next batch\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "\n",
        "        #Loss\n",
        "        loss = F.cross_entropy(output, target)\n",
        "\n",
        "        #Backprop\n",
        "        loss.backward()\n",
        "\n",
        "        #Optimization step (Parameter Update)\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "    #Log results of each epoch. CARE: Epoch will be an integer passed so the parameter is ONLY for tracking here. train(...) needs to be called in a loop based on how many epochs are to be trained (each epoch's index passed as epoch)\n",
        "    if display:\n",
        "      print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "          epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "          100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    #Set model to test mode ----------------------------------CARE WHEN NORMALIZATION, DIFFERENT FOR TRAIN/TEST---------------------\n",
        "    model.eval()\n",
        "\n",
        "\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    #no_grad() will not hold grad, which is fine since we do not want to calculate gradient as we are only interested in checking the prediction from the forward pass.\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "\n",
        "            #Test Loss\n",
        "            test_loss += F.cross_entropy(output, target, size_average=False).item() # sum up batch loss\n",
        "\n",
        "            #Predicted class\n",
        "            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "\n",
        "            #Number of correct predictions in the batch to update overall total of correct predictions\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    #Average test loss over all dataset\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    #Log results\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n",
        "\n",
        "    #Return Accuracy Percent\n",
        "    return 100. * correct / len(test_loader.dataset)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyoKo78yE3xd"
      },
      "source": [
        "# Define the Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "pzASGzm4MlPM"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torchvision.models as models\n",
        "\n",
        "class Net(torch.nn.Module):\n",
        "    '''\n",
        "    Constructor. Define all layers (These were chosen through trying different variations by starting with 2-3 convolution layers and adding batchNorm and pooling between them as needed, with different parameters)\n",
        "    '''\n",
        "    def __init__(self, finetune_backbones):\n",
        "        super(Net, self).__init__()\n",
        "        self.model =  models.resnet50(pretrained=True)\n",
        "\n",
        "        # FT backbone (before output layers. freeze/unfreeze)\n",
        "        self.finetune_backbones = finetune_backbones\n",
        "        for i, param in enumerate(self.model.parameters()):\n",
        "          param.requires_grad = self.finetune_backbones\n",
        "\n",
        "\n",
        "        #New output head for the target task\n",
        "        in_features = self.model.fc.in_features #The fc layer of resenet50 is Linear(in_features=2048, out_features=1000, bias=True) so storing the 2048 and replacing this to map from 2048 to numClasses for target task ====can see the fc layer like this: backbone = models.resnet50(pretrained=True) => print(backbone.fc)\n",
        "        targetTaskOutFeatures = 9 # num of classes in target task\n",
        "        classifier = nn.Linear(in_features, targetTaskOutFeatures, bias=True)  # Create a new classifier\n",
        "        classifier.weight.requires_grad = True\n",
        "        classifier.bias.requires_grad = True\n",
        "        self.model.fc = classifier  # Replace the classifier layer\n",
        "\n",
        "        # self.layers = nn.ModuleList()\n",
        "\n",
        "        # # 3 Channels in (RGB at the start is what image channels are) and 16 channels out (arbitrarily chose 16)\n",
        "        # self.layers+=[nn.Conv2d(3, 16,  kernel_size=3) ,\n",
        "        #               nn.ReLU(inplace=True)]\n",
        "\n",
        "        # # Batch norm layer to normalize the tensor produced from convolution so covariances are not too high and this can help avoid issues like oscillating loss\n",
        "        # self.layers+=[nn.BatchNorm2d(16)]\n",
        "\n",
        "        # # Pooling to reduce number of params to learn so training time is improved by reducing dimension (e.g. image size) as it passes through the Net\n",
        "        # # basically as if multiple pixels would share the same parameter so 1 gradient is calculated between multiple pixels to allow training without needing higher number of computations (less gradients to calculate)\n",
        "        # self.layers+=[nn.MaxPool2d(kernel_size= 2, stride=2, padding= 0)]\n",
        "\n",
        "        # self.layers+=[nn.Conv2d(16, 32,  kernel_size=3),\n",
        "        #               nn.ReLU(inplace=True)]\n",
        "\n",
        "        # self.layers+=[nn.MaxPool2d(kernel_size= 2, stride=2, padding= 0)]\n",
        "\n",
        "        # self.layers+=[nn.Conv2d(32, 32,  kernel_size=3),\n",
        "        #               nn.ReLU(inplace=True)]\n",
        "\n",
        "        # self.layers+=[nn.MaxPool2d(kernel_size= 2, stride=2, padding= 0)]\n",
        "\n",
        "\n",
        "        # '''\n",
        "        # Linear layers after flattening\n",
        "        # # '''\n",
        "        # self.fc1 = nn.Linear(32*26*26, 64) #NEED TO MODIFY first argument to output of previous layers' size product of each observation. THIS BASED ON LAST INPUT SIZE (Changes as we do convolutions, pooling, etc)\n",
        "        # self.layer_norm1 = nn.LayerNorm(64)\n",
        "        # self.fc2 = nn.Linear(64, 30)\n",
        "        # self.layer_norm2 = nn.LayerNorm(30)\n",
        "        # self.fc3 = nn.Linear(30, 9) # Linear layer from X neurons to Y where y is number of classes being predicted\n",
        "    '''\n",
        "    Forward Pass\n",
        "    '''\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.model(x)\n",
        "        return x\n",
        "        # for i in range(len(self.layers)):\n",
        "        #   #print(f'Input size before layer: {self.layers[i]} --- size: {x.shape}')\n",
        "        #   x = self.layers[i](x)\n",
        "\n",
        "        #print(f'Input size before flattening convolution layers result -> {x.shape}')\n",
        "        # outChannelsHeightWidthproduct = x.shape[1]*x.shape[2]*x.shape[3]\n",
        "        # x = x.view(-1, outChannelsHeightWidthproduct)\n",
        "\n",
        "\n",
        "        # x = nn.functional.relu(self.fc1(x))\n",
        "\n",
        "\n",
        "        # x = self.layer_norm1(x)\n",
        "        # x = nn.functional.relu(self.fc2(x))\n",
        "        # x = self.layer_norm2(x)\n",
        "        # x = self.fc3(x)\n",
        "        #print(f'Final input size -> {x.shape}')\n",
        "        #return x\n",
        "\n",
        "\n",
        "    '''\n",
        "    Turn finetuning of the backbone layers on or off.\n",
        "    '''\n",
        "    def FTBackbone(backbone, boolVal):\n",
        "      for i, param in enumerate(backbone.parameters()):\n",
        "        param.requires_grad = boolVal\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTqusmWBE7_X"
      },
      "source": [
        "# Execute training and testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "naD0uVMUCF4e"
      },
      "outputs": [],
      "source": [
        "def evaluate(train_data, val_data, epochs, b_size, lr, momentum, weight_decay, optimizer_name, finetune_backbones):\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    '''\n",
        "    Send to dataloader\n",
        "    '''\n",
        "    #Make use of dataloader so we can easily work with it later on.\n",
        "    train_loader = torch.utils.data.DataLoader(train_data,\n",
        "                                              batch_size=b_size,\n",
        "                                              shuffle=True,\n",
        "                                              drop_last = True)\n",
        "\n",
        "    val_loader = torch.utils.data.DataLoader(val_data,\n",
        "                                            batch_size=b_size,\n",
        "                                            shuffle=False,\n",
        "                                            drop_last = True)\n",
        "\n",
        "\n",
        "    '''\n",
        "    Initialize model, send to device and set optimizer\n",
        "    '''\n",
        "    model = Net(finetune_backbones).to(device)\n",
        "\n",
        "    #Optimizer\n",
        "    if optimizer_name == \"SGD\":\n",
        "      print(f'USING OPTIMIZER -------- SGD')\n",
        "      optimizer = torch.optim.SGD(model.parameters(),lr=lr, momentum= momentum, weight_decay= weight_decay)\n",
        "    else:\n",
        "      print(f'USING OPTIMIZER -------- ADAM')\n",
        "      optimizer = torch.optim.Adam(model.parameters(),lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "\n",
        "\n",
        "    '''\n",
        "    Train model for certain epochs\n",
        "    '''\n",
        "    for epoch in range(epochs):\n",
        "      train(model, device, train_loader, optimizer, epoch, display= True)# epoch%5==0)\n",
        "\n",
        "    '''\n",
        "    Test model and results (will run for each seed and store result so all seed accuracies can be aggregated)\n",
        "    '''\n",
        "    acc = test(model, device, val_loader)\n",
        "\n",
        "    #Average accuracies over all random state seeds\n",
        "    print('='*30)\n",
        "    print(f'Hyperparameters used were: \\n epochs, b_size, lr, momentum, weight_decay\\n {epochs}, {b_size}, {lr}, {momentum}, {weight_decay}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "EJvxpTSQ0SfC",
        "outputId": "4374c8b5-3089-4726-c733-3ceb098f146f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 155MB/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-9ba4c90057a6>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mfinetune_backbones\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinetune_backbones\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-10-fc502c648b4f>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(train_data, val_data, epochs, b_size, lr, momentum, weight_decay, optimizer_name, finetune_backbones)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mInitialize\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msend\u001b[0m \u001b[0mto\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mset\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     '''\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinetune_backbones\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m#Optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1143\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1145\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m     def register_full_backward_pre_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 820\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    821\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1141\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m   1142\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m-> 1143\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'CUDA_MODULE_LOADING'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CUDA_MODULE_LOADING'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'LAZY'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
          ]
        }
      ],
      "source": [
        "epochs = 20\n",
        "b_size = 128\n",
        "lr = 0.0001\n",
        "momentum = 0\n",
        "weight_decay = 0.0005\n",
        "optimizer_name = 'SGD'\n",
        "finetune_backbones = False\n",
        "\n",
        "evaluate(train_data, test_data, epochs, b_size, lr, momentum, weight_decay, optimizer_name, finetune_backbones)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "4bQxeevo4SXu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMWZkUan4CEkswX7fA2rvo2",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}