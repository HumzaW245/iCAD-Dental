{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HumzaW245/iCAD-Dental/blob/main/iCAD_Dental_Coding_Test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djaAjDFIQ0K3"
      },
      "source": [
        "# Downloading data using kaggle API\n",
        "\n",
        "Read comment by 'Nikhil Ojha' for simple instructions on how to do download dataset (https://www.kaggle.com/discussions/general/74235)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "uZDeetCrLF-A"
      },
      "outputs": [],
      "source": [
        "! pip install -q kaggle\n",
        "from google.colab import files\n",
        "files.upload() #Upload kaggle.json (it contains API key to access kaggle datasets)\n",
        "\n",
        "\n",
        "from IPython.display import clear_output\n",
        "clear_output() #To clear output printed since previous lines will show kaggle API key information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ORn2TnysN73K"
      },
      "outputs": [],
      "source": [
        "!rm -r ~/.kaggle\n",
        "!mkdir ~/.kaggle\n",
        "!mv ./kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "7QsVnjvVOWev"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1BBnZrhOYi9",
        "outputId": "34b27ab2-27fb-4b8f-aa52-7d1520aaf8f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "isic-2019-skin-lesion-images-for-classification.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ],
      "source": [
        "# To download dataset, go to dataset ->https://www.kaggle.com/datasets/salviohexia/isic-2019-skin-lesion-images-for-classification/discussion\n",
        "# Then click 3 dots menu -> 'Copy API Command'\n",
        "# since in google colab, need to do ! first -> ! <pastedAPIcommandHere>\n",
        "\n",
        "! kaggle datasets download -d salviohexia/isic-2019-skin-lesion-images-for-classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "zHHKrQPkPzHy"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile('isic-2019-skin-lesion-images-for-classification.zip', 'r')\n",
        "zip_ref.extractall('/content/ISIC2019')\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAJ-yg7nR5nj",
        "outputId": "e226f597-8ce6-425e-fb6d-f989830e0fc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              image  MEL   NV  BCC   AK  BKL   DF  VASC  SCC  UNK Class  \\\n",
            "0      ISIC_0000000  0.0  1.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0    NV   \n",
            "1      ISIC_0000001  0.0  1.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0    NV   \n",
            "2      ISIC_0000002  1.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0   MEL   \n",
            "3      ISIC_0000003  0.0  1.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0    NV   \n",
            "4      ISIC_0000004  1.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0   MEL   \n",
            "...             ...  ...  ...  ...  ...  ...  ...   ...  ...  ...   ...   \n",
            "25321  ISIC_0073240  0.0  1.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0    NV   \n",
            "25322  ISIC_0073241  1.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0   MEL   \n",
            "25323  ISIC_0073244  0.0  1.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0    NV   \n",
            "25324  ISIC_0073245  0.0  1.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0    NV   \n",
            "25325  ISIC_0073246  0.0  0.0  1.0  0.0  0.0  0.0   0.0  0.0  0.0   BCC   \n",
            "\n",
            "       Class_Index  \n",
            "0                1  \n",
            "1                1  \n",
            "2                0  \n",
            "3                1  \n",
            "4                0  \n",
            "...            ...  \n",
            "25321            1  \n",
            "25322            0  \n",
            "25323            1  \n",
            "25324            1  \n",
            "25325            2  \n",
            "\n",
            "[25326 rows x 12 columns]\n"
          ]
        }
      ],
      "source": [
        "# ctrl-f 'In [13]' if want details of making a complete dataset using the metadata too -> https://www.kaggle.com/code/shonenkov/merge-external-data/notebook\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Specify the path to the CSV files\n",
        "metadata_csv_file_path = '/content/ISIC2019/ISIC_2019_Training_Metadata.csv'\n",
        "data_csv_file_path = '/content/ISIC2019/ISIC_2019_Training_GroundTruth.csv'\n",
        "\n",
        "\n",
        "\n",
        "# Load the metadata and main data from the CSV file\n",
        "metadata_df = pd.read_csv(metadata_csv_file_path)\n",
        "main_df = pd.read_csv(data_csv_file_path)\n",
        "\n",
        "\n",
        "#Getting class name and index column (index is used to make predictions more easily)\n",
        "main_df['Class'] = main_df.apply(lambda row: main_df.columns[(row == 1)].tolist()[0], axis=1)\n",
        "class_idx_map = {'MEL':0, 'NV':1, 'BCC':2, 'AK':3, 'BKL':4, 'DF':5, 'VASC':6, 'SCC':7, 'UNK':8}\n",
        "main_df['Class_Index'] = main_df['Class'].apply(lambda class_name: class_idx_map[class_name])\n",
        "\n",
        "\n",
        "print(main_df.head(-5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "KV-D2uwjgsGw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ml4MA_rITYAR"
      },
      "outputs": [],
      "source": [
        "dataset_dir = '/content/ISIC2019/'\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "# Define a custom dataset class\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, root_dir, dataframe, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.dataframe = dataframe\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        label = self.dataframe.iloc[idx]['Class_Index']\n",
        "        class_name = self.dataframe.iloc[idx]['Class']\n",
        "        #Get label index to tensor\n",
        "        label = torch.tensor(label)\n",
        "\n",
        "        #Get image\n",
        "        img_id = self.dataframe.iloc[idx, 0]\n",
        "        img_path = os.path.join(self.root_dir, class_name + '/' + img_id + '.jpg')  # Assuming images are in JPEG format\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        #Apply transformations to image\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfY6nyO9BWFd"
      },
      "source": [
        "# DataLoaders and Transformations *************CHECK TRANSF THAT SHOULD BE APPLIED...maybe some standard one"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "E_avZmV-gQew"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data frame into training and test sets\n",
        "train_df, test_df = train_test_split(main_df, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# Transformations to use for preprocessing (Arbitrarily chose these to have standardized data)\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Resize the image to a common size\n",
        "    transforms.ToTensor(),  # Convert PIL Image to PyTorch tensor\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize using ImageNet statistics\n",
        "])\n",
        "\n",
        "train_data = CustomDataset(dataset_dir, train_df, transform = data_transforms)\n",
        "test_data = CustomDataset(dataset_dir, test_df, transform = data_transforms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "-yb_xjogMNn2"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XiXBBLwpCUVv"
      },
      "source": [
        "# Train and Test functions for how training will be done"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "CXOjTv4kUSG4"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "def train(model, device, train_loader, optimizer, epoch, display=True):\n",
        "    #Set model to training mode ----------------------------------CARE WHEN NORMALIZATION, DIFFERENT FOR TRAIN/TEST---------------------\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "\n",
        "        #Data to device\n",
        "        data, target = data.to(device), target.to(device)\n",
        "\n",
        "        #Reset grad for next batch\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "\n",
        "        #Loss\n",
        "        loss = F.cross_entropy(output, target)\n",
        "\n",
        "        #Backprop\n",
        "        loss.backward()\n",
        "\n",
        "        #Optimization step (Parameter Update)\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "    #Log results of each epoch. CARE: Epoch will be an integer passed so the parameter is ONLY for tracking here. train(...) needs to be called in a loop based on how many epochs are to be trained (each epoch's index passed as epoch)\n",
        "    if display:\n",
        "      print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "          epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "          100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    #Set model to test mode ----------------------------------CARE WHEN NORMALIZATION, DIFFERENT FOR TRAIN/TEST---------------------\n",
        "    model.eval()\n",
        "\n",
        "\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    #no_grad() will not hold grad, which is fine since we do not want to calculate gradient as we are only interested in checking the prediction from the forward pass.\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "\n",
        "            #Test Loss\n",
        "            test_loss += F.cross_entropy(output, target, size_average=False).item() # sum up batch loss\n",
        "\n",
        "            #Predicted class\n",
        "            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "\n",
        "            #Number of correct predictions in the batch to update overall total of correct predictions\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    #Average test loss over all dataset\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    #Log results\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n",
        "\n",
        "    #Return Accuracy Percent\n",
        "    return 100. * correct / len(test_loader.dataset)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyoKo78yE3xd"
      },
      "source": [
        "# Define the Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "pzASGzm4MlPM"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torchvision.models as models\n",
        "\n",
        "class Net(torch.nn.Module):\n",
        "    '''\n",
        "    Constructor. Define all layers (These were chosen through trying different variations by starting with 2-3 convolution layers and adding batchNorm and pooling between them as needed, with different parameters)\n",
        "    '''\n",
        "    def __init__(self, finetune_backbones):\n",
        "        super(Net, self).__init__()\n",
        "        self.model =  models.resnet50(pretrained=True)\n",
        "\n",
        "        # FT backbone (before output layers. freeze/unfreeze)\n",
        "        self.finetune_backbones = finetune_backbones\n",
        "        for i, param in enumerate(self.model.parameters()):\n",
        "          param.requires_grad = self.finetune_backbones\n",
        "\n",
        "\n",
        "        #New output head for the target task\n",
        "        in_features = self.model.fc.in_features #The fc layer of resenet50 is Linear(in_features=2048, out_features=1000, bias=True) so storing the 2048 and replacing this to map from 2048 to numClasses for target task ====can see the fc layer like this: backbone = models.resnet50(pretrained=True) => print(backbone.fc)\n",
        "        targetTaskOutFeatures = 9 # num of classes in target task\n",
        "        classifier = nn.Linear(in_features, targetTaskOutFeatures, bias=True)  # Create a new classifier\n",
        "        classifier.weight.requires_grad = True\n",
        "        classifier.bias.requires_grad = True\n",
        "        self.model.fc = classifier  # Replace the classifier layer\n",
        "\n",
        "        # self.layers = nn.ModuleList()\n",
        "\n",
        "        # # 3 Channels in (RGB at the start is what image channels are) and 16 channels out (arbitrarily chose 16)\n",
        "        # self.layers+=[nn.Conv2d(3, 16,  kernel_size=3) ,\n",
        "        #               nn.ReLU(inplace=True)]\n",
        "\n",
        "        # # Batch norm layer to normalize the tensor produced from convolution so covariances are not too high and this can help avoid issues like oscillating loss\n",
        "        # self.layers+=[nn.BatchNorm2d(16)]\n",
        "\n",
        "        # # Pooling to reduce number of params to learn so training time is improved by reducing dimension (e.g. image size) as it passes through the Net\n",
        "        # # basically as if multiple pixels would share the same parameter so 1 gradient is calculated between multiple pixels to allow training without needing higher number of computations (less gradients to calculate)\n",
        "        # self.layers+=[nn.MaxPool2d(kernel_size= 2, stride=2, padding= 0)]\n",
        "\n",
        "        # self.layers+=[nn.Conv2d(16, 32,  kernel_size=3),\n",
        "        #               nn.ReLU(inplace=True)]\n",
        "\n",
        "        # self.layers+=[nn.MaxPool2d(kernel_size= 2, stride=2, padding= 0)]\n",
        "\n",
        "        # self.layers+=[nn.Conv2d(32, 32,  kernel_size=3),\n",
        "        #               nn.ReLU(inplace=True)]\n",
        "\n",
        "        # self.layers+=[nn.MaxPool2d(kernel_size= 2, stride=2, padding= 0)]\n",
        "\n",
        "\n",
        "        # '''\n",
        "        # Linear layers after flattening\n",
        "        # # '''\n",
        "        # self.fc1 = nn.Linear(32*26*26, 64) #NEED TO MODIFY first argument to output of previous layers' size product of each observation. THIS BASED ON LAST INPUT SIZE (Changes as we do convolutions, pooling, etc)\n",
        "        # self.layer_norm1 = nn.LayerNorm(64)\n",
        "        # self.fc2 = nn.Linear(64, 30)\n",
        "        # self.layer_norm2 = nn.LayerNorm(30)\n",
        "        # self.fc3 = nn.Linear(30, 9) # Linear layer from X neurons to Y where y is number of classes being predicted\n",
        "    '''\n",
        "    Forward Pass\n",
        "    '''\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.model(x)\n",
        "        return x\n",
        "        # for i in range(len(self.layers)):\n",
        "        #   #print(f'Input size before layer: {self.layers[i]} --- size: {x.shape}')\n",
        "        #   x = self.layers[i](x)\n",
        "\n",
        "        #print(f'Input size before flattening convolution layers result -> {x.shape}')\n",
        "        # outChannelsHeightWidthproduct = x.shape[1]*x.shape[2]*x.shape[3]\n",
        "        # x = x.view(-1, outChannelsHeightWidthproduct)\n",
        "\n",
        "\n",
        "        # x = nn.functional.relu(self.fc1(x))\n",
        "\n",
        "\n",
        "        # x = self.layer_norm1(x)\n",
        "        # x = nn.functional.relu(self.fc2(x))\n",
        "        # x = self.layer_norm2(x)\n",
        "        # x = self.fc3(x)\n",
        "        #print(f'Final input size -> {x.shape}')\n",
        "        #return x\n",
        "\n",
        "\n",
        "    '''\n",
        "    Turn finetuning of the backbone layers on or off.\n",
        "    '''\n",
        "    def FTBackbone(backbone, boolVal):\n",
        "      for i, param in enumerate(backbone.parameters()):\n",
        "        param.requires_grad = boolVal\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTqusmWBE7_X"
      },
      "source": [
        "# Execute training and testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "naD0uVMUCF4e"
      },
      "outputs": [],
      "source": [
        "def evaluate(train_data, val_data, epochs, b_size, lr, momentum, weight_decay, optimizer_name, finetune_backbones):\n",
        "    device = 'cuda'\n",
        "    '''\n",
        "    Send to dataloader\n",
        "    '''\n",
        "    #Make use of dataloader so we can easily work with it later on.\n",
        "    train_loader = torch.utils.data.DataLoader(train_data,\n",
        "                                              batch_size=b_size,\n",
        "                                              shuffle=True,\n",
        "                                              drop_last = True)\n",
        "\n",
        "    val_loader = torch.utils.data.DataLoader(val_data,\n",
        "                                            batch_size=b_size,\n",
        "                                            shuffle=False,\n",
        "                                            drop_last = True)\n",
        "\n",
        "\n",
        "    '''\n",
        "    Initialize model, send to device and set optimizer\n",
        "    '''\n",
        "    model = Net(finetune_backbones).to(device)\n",
        "\n",
        "    #Optimizer\n",
        "    if optimizer_name == \"SGD\":\n",
        "      print(f'USING OPTIMIZER -------- SGD')\n",
        "      optimizer = torch.optim.SGD(model.parameters(),lr=lr, momentum= momentum, weight_decay= weight_decay)\n",
        "    else:\n",
        "      print(f'USING OPTIMIZER -------- ADAM')\n",
        "      optimizer = torch.optim.Adam(model.parameters(),lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "\n",
        "\n",
        "    '''\n",
        "    Train model for certain epochs\n",
        "    '''\n",
        "    for epoch in range(epochs):\n",
        "      train(model, device, train_loader, optimizer, epoch, display= True)# epoch%5==0)\n",
        "\n",
        "    '''\n",
        "    Test model and results (will run for each seed and store result so all seed accuracies can be aggregated)\n",
        "    '''\n",
        "    acc = test(model, device, val_loader)\n",
        "\n",
        "    #Average accuracies over all random state seeds\n",
        "    print('='*30)\n",
        "    print(f'Hyperparameters used were: \\n epochs, b_size, lr, momentum, weight_decay\\n {epochs}, {b_size}, {lr}, {momentum}, {weight_decay}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJvxpTSQ0SfC",
        "outputId": "edf4c67a-8b2b-49a8-f2d4-bf8250c6d33f"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "USING OPTIMIZER -------- SGD\n",
            "Train Epoch: 0 [20224/20264 (100%)]\tLoss: 1.753199\n",
            "Train Epoch: 1 [20224/20264 (100%)]\tLoss: 1.315841\n",
            "Train Epoch: 2 [20224/20264 (100%)]\tLoss: 1.125319\n",
            "Train Epoch: 3 [20224/20264 (100%)]\tLoss: 1.271076\n",
            "Train Epoch: 4 [20224/20264 (100%)]\tLoss: 1.110852\n",
            "Train Epoch: 5 [20224/20264 (100%)]\tLoss: 1.119736\n",
            "Train Epoch: 6 [20224/20264 (100%)]\tLoss: 1.302057\n",
            "Train Epoch: 7 [20224/20264 (100%)]\tLoss: 1.365488\n",
            "Train Epoch: 8 [20224/20264 (100%)]\tLoss: 0.992661\n",
            "Train Epoch: 9 [20224/20264 (100%)]\tLoss: 1.117083\n",
            "Train Epoch: 10 [20224/20264 (100%)]\tLoss: 1.281827\n",
            "Train Epoch: 11 [20224/20264 (100%)]\tLoss: 1.525354\n",
            "Train Epoch: 12 [20224/20264 (100%)]\tLoss: 1.069070\n",
            "Train Epoch: 13 [20224/20264 (100%)]\tLoss: 1.354605\n",
            "Train Epoch: 14 [20224/20264 (100%)]\tLoss: 0.926355\n",
            "Train Epoch: 15 [20224/20264 (100%)]\tLoss: 1.098387\n",
            "Train Epoch: 16 [20224/20264 (100%)]\tLoss: 1.069061\n",
            "Train Epoch: 17 [20224/20264 (100%)]\tLoss: 0.967568\n",
            "Train Epoch: 18 [20224/20264 (100%)]\tLoss: 1.180928\n",
            "Train Epoch: 19 [20224/20264 (100%)]\tLoss: 1.203889\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.0768, Accuracy: 3155/5067 (62.27%)\n",
            "\n",
            "==============================\n",
            "Hyperparameters used were: \n",
            " epochs, b_size, lr, momentum, weight_decay\n",
            " 20, 32, 0.0001, 0, 0.0005\n"
          ]
        }
      ],
      "source": [
        "epochs = 20\n",
        "b_size = 32\n",
        "lr = 0.0001\n",
        "momentum = 0\n",
        "weight_decay = 0.0005\n",
        "optimizer_name = 'SGD'\n",
        "finetune_backbones = False\n",
        "\n",
        "evaluate(train_data, test_data, epochs, b_size, lr, momentum, weight_decay, optimizer_name, finetune_backbones)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "4bQxeevo4SXu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPKdWaaw7eVc/ySI70O9Bho",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}