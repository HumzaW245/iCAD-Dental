{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "djaAjDFIQ0K3"
      ],
      "authorship_tag": "ABX9TyPhqsJI/+RgcFx5zR49IyAv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HumzaW245/iCAD-Dental/blob/main/iCAD_Dental_Coding_Test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Downloading data using kaggle API\n",
        "\n",
        "Read comment by 'Nikhil Ojha' for simple instructions on how to do download dataset (https://www.kaggle.com/discussions/general/74235)"
      ],
      "metadata": {
        "id": "djaAjDFIQ0K3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uZDeetCrLF-A"
      },
      "outputs": [],
      "source": [
        "! pip install -q kaggle\n",
        "from google.colab import files\n",
        "files.upload() #Upload kaggle.json (it contains API key to access kaggle datasets)\n",
        "\n",
        "\n",
        "from IPython.display import clear_output\n",
        "clear_output() #To clear output printed since previous lines will show kaggle API key information"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r ~/.kaggle\n",
        "!mkdir ~/.kaggle\n",
        "!mv ./kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "ORn2TnysN73K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7QsVnjvVOWev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To download dataset, go to dataset ->https://www.kaggle.com/datasets/salviohexia/isic-2019-skin-lesion-images-for-classification/discussion\n",
        "# Then click 3 dots menu -> 'Copy API Command'\n",
        "# since in google colab, need to do ! first -> ! <pastedAPIcommandHere>\n",
        "\n",
        "! kaggle datasets download -d salviohexia/isic-2019-skin-lesion-images-for-classification"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1BBnZrhOYi9",
        "outputId": "fb0509c2-3b4d-4743-f948-40fbfee324da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "isic-2019-skin-lesion-images-for-classification.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile('isic-2019-skin-lesion-images-for-classification.zip', 'r')\n",
        "zip_ref.extractall('/content/ISIC2019')\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "zHHKrQPkPzHy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ctrl-f 'In [13]' if want details of making a complete dataset using the metadata too -> https://www.kaggle.com/code/shonenkov/merge-external-data/notebook\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Specify the path to the CSV files\n",
        "metadata_csv_file_path = '/content/ISIC2019/ISIC_2019_Training_Metadata.csv'\n",
        "data_csv_file_path = '/content/ISIC2019/ISIC_2019_Training_GroundTruth.csv'\n",
        "\n",
        "\n",
        "\n",
        "# Load the metadata and main data from the CSV file\n",
        "metadata_df = pd.read_csv(metadata_csv_file_path)\n",
        "main_df = pd.read_csv(data_csv_file_path)\n",
        "\n",
        "\n",
        "#Getting class name and index column (index is used to make predictions more easily)\n",
        "main_df['Class'] = main_df.apply(lambda row: main_df.columns[(row == 1)].tolist()[0], axis=1)\n",
        "class_idx_map = {'MEL':0, 'NV':1, 'BCC':2, 'AK':3, 'BKL':4, 'DF':5, 'VASC':6, 'SCC':7, 'UNK':8}\n",
        "main_df['Class_Index'] = main_df['Class'].apply(lambda class_name: class_idx_map[class_name])\n",
        "\n",
        "\n",
        "print(main_df.head(-5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAJ-yg7nR5nj",
        "outputId": "ba82dee7-3877-4326-e435-e43b77bce33f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              image  MEL   NV  BCC   AK  BKL   DF  VASC  SCC  UNK Class  \\\n",
            "0      ISIC_0000000  0.0  1.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0    NV   \n",
            "1      ISIC_0000001  0.0  1.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0    NV   \n",
            "2      ISIC_0000002  1.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0   MEL   \n",
            "3      ISIC_0000003  0.0  1.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0    NV   \n",
            "4      ISIC_0000004  1.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0   MEL   \n",
            "...             ...  ...  ...  ...  ...  ...  ...   ...  ...  ...   ...   \n",
            "25321  ISIC_0073240  0.0  1.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0    NV   \n",
            "25322  ISIC_0073241  1.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0   MEL   \n",
            "25323  ISIC_0073244  0.0  1.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0    NV   \n",
            "25324  ISIC_0073245  0.0  1.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0    NV   \n",
            "25325  ISIC_0073246  0.0  0.0  1.0  0.0  0.0  0.0   0.0  0.0  0.0   BCC   \n",
            "\n",
            "       Class_Index  \n",
            "0                1  \n",
            "1                1  \n",
            "2                0  \n",
            "3                1  \n",
            "4                0  \n",
            "...            ...  \n",
            "25321            1  \n",
            "25322            0  \n",
            "25323            1  \n",
            "25324            1  \n",
            "25325            2  \n",
            "\n",
            "[25326 rows x 12 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KV-D2uwjgsGw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_dir = '/content/ISIC2019/'\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "# Define a custom dataset class\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, root_dir, dataframe, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.dataframe = dataframe\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        label = self.dataframe.iloc[idx]['Class_Index']\n",
        "        class_name = self.dataframe.iloc[idx]['Class']\n",
        "        #Get label index to tensor\n",
        "        label = torch.tensor(label)\n",
        "\n",
        "        #Get image\n",
        "        img_id = self.dataframe.iloc[idx, 0]\n",
        "        img_path = os.path.join(self.root_dir, class_name + '/' + img_id + '.jpg')  # Assuming images are in JPEG format\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        #Apply transformations to image\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n"
      ],
      "metadata": {
        "id": "ml4MA_rITYAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DataLoaders and Transformations *************CHECK TRANSF THAT SHOULD BE APPLIED...maybe some standard one"
      ],
      "metadata": {
        "id": "lfY6nyO9BWFd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data frame into training and test sets\n",
        "train_df, test_df = train_test_split(main_df, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "\n",
        "train_data = CustomDataset(dataset_dir, train_df, transform = None)\n",
        "test_data = CustomDataset(dataset_dir, test_df, transform = None)"
      ],
      "metadata": {
        "id": "E_avZmV-gQew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "-yb_xjogMNn2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train and Test functions for how training will be done"
      ],
      "metadata": {
        "id": "XiXBBLwpCUVv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "def train(model, device, train_loader, optimizer, epoch, display=True):\n",
        "    #Set model to training mode ----------------------------------CARE WHEN NORMALIZATION, DIFFERENT FOR TRAIN/TEST---------------------\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "\n",
        "        #Data to device\n",
        "        data, target = data.to(device), target.to(device)\n",
        "\n",
        "        #Reset grad for next batch\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "\n",
        "        #Loss\n",
        "        loss = F.cross_entropy(output, target)\n",
        "\n",
        "        #Backprop\n",
        "        loss.backward()\n",
        "\n",
        "        #Optimization step (Parameter Update)\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "    #Log results of each epoch. CARE: Epoch will be an integer passed so the parameter is ONLY for tracking here. train(...) needs to be called in a loop based on how many epochs are to be trained (each epoch's index passed as epoch)\n",
        "    if display:\n",
        "      print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "          epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "          100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    #Set model to test mode ----------------------------------CARE WHEN NORMALIZATION, DIFFERENT FOR TRAIN/TEST---------------------\n",
        "    model.eval()\n",
        "\n",
        "\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    #no_grad() will not hold grad, which is fine since we do not want to calculate gradient as we are only interested in checking the prediction from the forward pass.\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "\n",
        "            #Test Loss\n",
        "            test_loss += F.cross_entropy(output, target, size_average=False).item() # sum up batch loss\n",
        "\n",
        "            #Predicted class\n",
        "            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "\n",
        "            #Number of correct predictions in the batch to update overall total of correct predictions\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    #Average test loss over all dataset\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    #Log results\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n",
        "\n",
        "    #Return Accuracy Percent\n",
        "    return 100. * correct / len(test_loader.dataset)\n",
        "\n"
      ],
      "metadata": {
        "id": "CXOjTv4kUSG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define the Network"
      ],
      "metadata": {
        "id": "uyoKo78yE3xd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(torch.nn.Module):\n",
        "    '''\n",
        "    Constructor. Define all layers (These were chosen through trying different variations by starting with 2-3 convolution layers and adding batchNorm and pooling between them as needed, with different parameters)\n",
        "    '''\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.layers = nn.ModuleList()\n",
        "\n",
        "        # 3 Channels in (RGB at the start is what image channels are) and 16 channels out (arbitrarily chose 16)\n",
        "        self.layers+=[nn.Conv2d(3, 16,  kernel_size=3) ,\n",
        "                      nn.ReLU(inplace=True)]\n",
        "\n",
        "        # Batch norm layer to normalize the tensor produced from convolution so covariances are not too high and this can help avoid issues like oscillating loss\n",
        "        self.layers+=[nn.BatchNorm2d(16)]\n",
        "\n",
        "        # Pooling to reduce number of params to learn so training time is improved by reducing dimension (e.g. image size) as it passes through the Net\n",
        "        # basically as if multiple pixels would share the same parameter so 1 gradient is calculated between multiple pixels to allow training without needing higher number of computations (less gradients to calculate)\n",
        "        self.layers+=[nn.MaxPool2d(kernel_size= 2, stride=2, padding= 1)]\n",
        "\n",
        "        self.layers+=[nn.Conv2d(16, 32,  kernel_size=3),\n",
        "                      nn.ReLU(inplace=True)]\n",
        "\n",
        "        self.layers+=[nn.MaxPool2d(kernel_size= 2, stride=2, padding= 1)]\n",
        "\n",
        "        self.layers+=[nn.Conv2d(32, 32,  kernel_size=3),\n",
        "                      nn.ReLU(inplace=True)]\n",
        "\n",
        "        self.layers+=[nn.MaxPool2d(kernel_size= 2, stride=1, padding= 1)]\n",
        "\n",
        "\n",
        "        '''\n",
        "        Linear layers after flattening\n",
        "        '''\n",
        "        self.fc1 = nn.Linear(32*7*7, 30) #NEED TO MODIFY first argument to output of previous layers' size product of each observation. THIS BASED ON LAST INPUT SIZE (Changes as we do convolutions, pooling, etc)\n",
        "        self.layer_norm1 = nn.LayerNorm(30)\n",
        "        self.fc2 = nn.Linear(30, 15)\n",
        "        self.layer_norm2 = nn.LayerNorm(15)\n",
        "        self.fc3 = nn.Linear(15, 9) # Linear layer from X neurons to Y where y is number of classes being predicted\n",
        "    '''\n",
        "    Forward Pass\n",
        "    '''\n",
        "    def forward(self, x):\n",
        "        for i in range(len(self.layers)):\n",
        "          print(f'Input size before layer: {self.layers[i]} --- size: {x.shape}')\n",
        "          x = self.layers[i](x)\n",
        "\n",
        "        print(f'Input size before flattening convolution layers result -> {x.shape}')\n",
        "        outChannelsHeightWidthproduct = x.shape[1]*x.shape[2]*x.shape[3]\n",
        "        x = x.view(-1, outChannelsHeightWidthproduct)\n",
        "\n",
        "\n",
        "        x = nn.functional.relu(self.fc1(x))\n",
        "\n",
        "\n",
        "        x = self.layer_norm1(x)\n",
        "        x = nn.functional.relu(self.fc2(x))\n",
        "        x = self.layer_norm2(x)\n",
        "        x = self.fc3(x)\n",
        "        #print(f'Final input size -> {x.shape}')\n",
        "        return x\n",
        "\n"
      ],
      "metadata": {
        "id": "pzASGzm4MlPM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Execute training and testing"
      ],
      "metadata": {
        "id": "eTqusmWBE7_X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def evaluate():\n",
        ""
      ],
      "metadata": {
        "id": "naD0uVMUCF4e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}