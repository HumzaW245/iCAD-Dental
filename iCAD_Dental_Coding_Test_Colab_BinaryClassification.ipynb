{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HumzaW245/iCAD-Dental/blob/main/iCAD_Dental_Coding_Test_Colab_BinaryClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djaAjDFIQ0K3"
      },
      "source": [
        "# Downloading data using kaggle API\n",
        "\n",
        "Read comment by 'Nikhil Ojha' for simple instructions on how to do download dataset (https://www.kaggle.com/discussions/general/74235)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "uZDeetCrLF-A"
      },
      "outputs": [],
      "source": [
        "! pip install -q kaggle\n",
        "from google.colab import files\n",
        "files.upload() #Upload kaggle.json (it contains API key to access kaggle datasets)\n",
        "\n",
        "\n",
        "\n",
        "from IPython.display import clear_output\n",
        "clear_output() #To clear output printed since previous lines will show kaggle API key information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ORn2TnysN73K"
      },
      "outputs": [],
      "source": [
        "!rm -r ~/.kaggle\n",
        "!mkdir ~/.kaggle\n",
        "!mv ./kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FSLV2-pq76Ix"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "7QsVnjvVOWev"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1BBnZrhOYi9",
        "outputId": "7b23132a-e704-4dc2-ce5e-ce9c5bfe67ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading isic-2019-skin-lesion-images-for-classification.zip to /content\n",
            "100% 9.09G/9.10G [01:07<00:00, 227MB/s]\n",
            "100% 9.10G/9.10G [01:07<00:00, 144MB/s]\n"
          ]
        }
      ],
      "source": [
        "# To download dataset, go to dataset ->https://www.kaggle.com/datasets/salviohexia/isic-2019-skin-lesion-images-for-classification/discussion\n",
        "# Then click 3 dots menu -> 'Copy API Command'\n",
        "# since in google colab, need to do ! first -> ! <pastedAPIcommandHere>\n",
        "\n",
        "! kaggle datasets download -d salviohexia/isic-2019-skin-lesion-images-for-classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "zHHKrQPkPzHy"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile('isic-2019-skin-lesion-images-for-classification.zip', 'r')\n",
        "zip_ref.extractall('/content/ISIC2019')\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAJ-yg7nR5nj",
        "outputId": "205e06f8-2449-46d7-91c2-15c6c9209d6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              image Original_Class   Class  Class_Index\n",
            "0      ISIC_0000000             NV  tumour            1\n",
            "1      ISIC_0000001             NV  tumour            1\n",
            "3      ISIC_0000003             NV  tumour            1\n",
            "5      ISIC_0000006             NV  tumour            1\n",
            "6      ISIC_0000007             NV  tumour            1\n",
            "...             ...            ...     ...          ...\n",
            "12407  ISIC_0033810             DF  tumour            1\n",
            "12444  ISIC_0033847             DF  tumour            1\n",
            "12457  ISIC_0033860             DF  tumour            1\n",
            "12488  ISIC_0033891             DF  tumour            1\n",
            "12732  ISIC_0034135             DF  tumour            1\n",
            "\n",
            "[12658 rows x 4 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-94f6d91b38c9>:32: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  reduced_df = reduced_df.append(class_subset)\n",
            "<ipython-input-9-94f6d91b38c9>:32: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  reduced_df = reduced_df.append(class_subset)\n",
            "<ipython-input-9-94f6d91b38c9>:32: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  reduced_df = reduced_df.append(class_subset)\n",
            "<ipython-input-9-94f6d91b38c9>:32: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  reduced_df = reduced_df.append(class_subset)\n",
            "<ipython-input-9-94f6d91b38c9>:32: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  reduced_df = reduced_df.append(class_subset)\n",
            "<ipython-input-9-94f6d91b38c9>:32: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  reduced_df = reduced_df.append(class_subset)\n",
            "<ipython-input-9-94f6d91b38c9>:32: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  reduced_df = reduced_df.append(class_subset)\n",
            "<ipython-input-9-94f6d91b38c9>:32: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  reduced_df = reduced_df.append(class_subset)\n"
          ]
        }
      ],
      "source": [
        "# ctrl-f 'In [13]' if want details of making a complete dataset using the metadata too -> https://www.kaggle.com/code/shonenkov/merge-external-data/notebook\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Specify the path to the CSV files\n",
        "metadata_csv_file_path = '/content/ISIC2019/ISIC_2019_Training_Metadata.csv'\n",
        "data_csv_file_path = '/content/ISIC2019/ISIC_2019_Training_GroundTruth.csv'\n",
        "\n",
        "\n",
        "\n",
        "# Load the metadata and main data from the CSV file\n",
        "metadata_df = pd.read_csv(metadata_csv_file_path)\n",
        "main_df = pd.read_csv(data_csv_file_path)\n",
        "\n",
        "\n",
        "#Getting class name and index column (index is used to make predictions more easily)\n",
        "\n",
        "#Original Class is different since in binary classificaion we make assumption SCC and VASC are one category and the rest are tumours\n",
        "main_df['Original_Class'] = main_df.apply(lambda row: main_df.columns[(row == 1)].tolist()[0], axis=1)\n",
        "\n",
        "\n",
        "def reduce_data_50pct(df):\n",
        "\n",
        "  class_counts = df['Original_Class'].value_counts()\n",
        "  #print(class_counts)\n",
        "  target_size = class_counts // 2  # Half of the original size for each class\n",
        "  #print(target_size)\n",
        "  reduced_df = pd.DataFrame(columns=df.columns)\n",
        "\n",
        "  for class_label, size in target_size.items():\n",
        "      class_subset = df[df['Original_Class'] == class_label].head(size)\n",
        "      reduced_df = reduced_df.append(class_subset)\n",
        "  return reduced_df\n",
        "\n",
        "main_df = reduce_data_50pct(main_df)\n",
        "#print(f\"NEW VALUE COUNTS: {main_df['Original_Class'].value_counts()}\")\n",
        "\n",
        "def mapBinaryClassName(className):\n",
        "  if className in ['VASC', 'SCC']:\n",
        "    return 'not_tumour'\n",
        "  else:\n",
        "    return 'tumour'\n",
        "\n",
        "main_df['Class'] = main_df['Original_Class'].apply(lambda original_class: mapBinaryClassName(original_class))\n",
        "\n",
        "#Binary classification we assume: SCC and VASC are one category and the rest are tumours\n",
        "class_idx_map = {'tumour': 1, 'not_tumour': 0}\n",
        "main_df['Class_Index'] = main_df['Class'].apply(lambda class_name: class_idx_map[class_name])\n",
        "\n",
        "\n",
        "main_df = main_df[['image', 'Original_Class', 'Class', 'Class_Index']]\n",
        "#print(main_df['Class'].value_counts())\n",
        "print(main_df.head(-5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "KV-D2uwjgsGw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ml4MA_rITYAR"
      },
      "outputs": [],
      "source": [
        "dataset_dir = '/content/ISIC2019/'\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "# Define a custom dataset class\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, root_dir, dataframe, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.dataframe = dataframe\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        label = self.dataframe.iloc[idx]['Class_Index']\n",
        "        class_name = self.dataframe.iloc[idx]['Original_Class']#Use original_class here since lookup in folders needs to be through original class names since no folder named e.g. 'tumour'\n",
        "        #Get label index to tensor\n",
        "        label = torch.tensor(label)\n",
        "\n",
        "        #Get image\n",
        "        img_id = self.dataframe.iloc[idx, 0]\n",
        "        img_path = os.path.join(self.root_dir, class_name + '/' + img_id + '.jpg')  # Assuming images are in JPEG format\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        #Apply transformations to image\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfY6nyO9BWFd"
      },
      "source": [
        "# DataLoaders and Transformations *************CHECK TRANSF THAT SHOULD BE APPLIED...maybe some standard one"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "E_avZmV-gQew"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data frame into training and test sets\n",
        "train_df, test_df = train_test_split(main_df, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# Transformations to use for preprocessing (Arbitrarily chose these to have standardized data)\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Resize the image to a common size\n",
        "    transforms.ToTensor(),  # Convert PIL Image to PyTorch tensor\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize using ImageNet statistics\n",
        "])\n",
        "\n",
        "train_data = CustomDataset(dataset_dir, train_df, transform = data_transforms)\n",
        "test_data = CustomDataset(dataset_dir, test_df, transform = data_transforms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "-yb_xjogMNn2"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XiXBBLwpCUVv"
      },
      "source": [
        "# Train and Test functions for how training will be done"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "CXOjTv4kUSG4"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "def train(model, device, train_loader, optimizer, epoch, display=True):\n",
        "    #Set model to training mode ----------------------------------CARE WHEN NORMALIZATION, DIFFERENT FOR TRAIN/TEST---------------------\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "\n",
        "        #Data to device\n",
        "        data, target = data.to(device), target.to(device)\n",
        "\n",
        "        #Reset grad for next batch\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "\n",
        "        #Loss\n",
        "        loss = F.cross_entropy(output, target)\n",
        "\n",
        "        #Backprop\n",
        "        loss.backward()\n",
        "\n",
        "        #Optimization step (Parameter Update)\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "    #Log results of each epoch. CARE: Epoch will be an integer passed so the parameter is ONLY for tracking here. train(...) needs to be called in a loop based on how many epochs are to be trained (each epoch's index passed as epoch)\n",
        "    if display:\n",
        "      print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "          epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "          100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    #Set model to test mode ----------------------------------CARE WHEN NORMALIZATION, DIFFERENT FOR TRAIN/TEST---------------------\n",
        "    model.eval()\n",
        "\n",
        "\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    #no_grad() will not hold grad, which is fine since we do not want to calculate gradient as we are only interested in checking the prediction from the forward pass.\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "\n",
        "            #Test Loss\n",
        "            test_loss += F.cross_entropy(output, target, size_average=False).item() # sum up batch loss\n",
        "\n",
        "            #Predicted class\n",
        "            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "\n",
        "            #Number of correct predictions in the batch to update overall total of correct predictions\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    #Average test loss over all dataset\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    #Log results\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n",
        "\n",
        "    #Return Accuracy Percent\n",
        "    return 100. * correct / len(test_loader.dataset)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyoKo78yE3xd"
      },
      "source": [
        "# Define the Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "pzASGzm4MlPM"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torchvision.models as models\n",
        "\n",
        "class Net(torch.nn.Module):\n",
        "    '''\n",
        "    Constructor. Define all layers (These were chosen through trying different variations by starting with 2-3 convolution layers and adding batchNorm and pooling between them as needed, with different parameters)\n",
        "    '''\n",
        "    def __init__(self, finetune_backbones):\n",
        "        super(Net, self).__init__()\n",
        "        self.model =  models.resnet50(pretrained=True)\n",
        "\n",
        "        # FT backbone (before output layers. freeze/unfreeze)\n",
        "        self.finetune_backbones = finetune_backbones\n",
        "        for i, param in enumerate(self.model.parameters()):\n",
        "          param.requires_grad = self.finetune_backbones\n",
        "\n",
        "\n",
        "        #New output head for the target task\n",
        "        in_features = self.model.fc.in_features #The fc layer of resenet50 is Linear(in_features=2048, out_features=1000, bias=True) so storing the 2048 and replacing this to map from 2048 to numClasses for target task ====can see the fc layer like this: backbone = models.resnet50(pretrained=True) => print(backbone.fc)\n",
        "        targetTaskOutFeatures = 2 # num of classes in target task\n",
        "        classifier = nn.Linear(in_features, targetTaskOutFeatures, bias=True)  # Create a new classifier\n",
        "        classifier.weight.requires_grad = True\n",
        "        classifier.bias.requires_grad = True\n",
        "        self.model.fc = classifier  # Replace the classifier layer\n",
        "\n",
        "        # self.layers = nn.ModuleList()\n",
        "\n",
        "        # # 3 Channels in (RGB at the start is what image channels are) and 16 channels out (arbitrarily chose 16)\n",
        "        # self.layers+=[nn.Conv2d(3, 16,  kernel_size=3) ,\n",
        "        #               nn.ReLU(inplace=True)]\n",
        "\n",
        "        # # Batch norm layer to normalize the tensor produced from convolution so covariances are not too high and this can help avoid issues like oscillating loss\n",
        "        # self.layers+=[nn.BatchNorm2d(16)]\n",
        "\n",
        "        # # Pooling to reduce number of params to learn so training time is improved by reducing dimension (e.g. image size) as it passes through the Net\n",
        "        # # basically as if multiple pixels would share the same parameter so 1 gradient is calculated between multiple pixels to allow training without needing higher number of computations (less gradients to calculate)\n",
        "        # self.layers+=[nn.MaxPool2d(kernel_size= 2, stride=2, padding= 0)]\n",
        "\n",
        "        # self.layers+=[nn.Conv2d(16, 32,  kernel_size=3),\n",
        "        #               nn.ReLU(inplace=True)]\n",
        "\n",
        "        # self.layers+=[nn.MaxPool2d(kernel_size= 2, stride=2, padding= 0)]\n",
        "\n",
        "        # self.layers+=[nn.Conv2d(32, 32,  kernel_size=3),\n",
        "        #               nn.ReLU(inplace=True)]\n",
        "\n",
        "        # self.layers+=[nn.MaxPool2d(kernel_size= 2, stride=2, padding= 0)]\n",
        "\n",
        "\n",
        "        # '''\n",
        "        # Linear layers after flattening\n",
        "        # # '''\n",
        "        # self.fc1 = nn.Linear(32*26*26, 64) #NEED TO MODIFY first argument to output of previous layers' size product of each observation. THIS BASED ON LAST INPUT SIZE (Changes as we do convolutions, pooling, etc)\n",
        "        # self.layer_norm1 = nn.LayerNorm(64)\n",
        "        # self.fc2 = nn.Linear(64, 30)\n",
        "        # self.layer_norm2 = nn.LayerNorm(30)\n",
        "        # self.fc3 = nn.Linear(30, 9) # Linear layer from X neurons to Y where y is number of classes being predicted\n",
        "    '''\n",
        "    Forward Pass\n",
        "    '''\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.model(x)\n",
        "        return x\n",
        "        # for i in range(len(self.layers)):\n",
        "        #   #print(f'Input size before layer: {self.layers[i]} --- size: {x.shape}')\n",
        "        #   x = self.layers[i](x)\n",
        "\n",
        "        #print(f'Input size before flattening convolution layers result -> {x.shape}')\n",
        "        # outChannelsHeightWidthproduct = x.shape[1]*x.shape[2]*x.shape[3]\n",
        "        # x = x.view(-1, outChannelsHeightWidthproduct)\n",
        "\n",
        "\n",
        "        # x = nn.functional.relu(self.fc1(x))\n",
        "\n",
        "\n",
        "        # x = self.layer_norm1(x)\n",
        "        # x = nn.functional.relu(self.fc2(x))\n",
        "        # x = self.layer_norm2(x)\n",
        "        # x = self.fc3(x)\n",
        "        #print(f'Final input size -> {x.shape}')\n",
        "        #return x\n",
        "\n",
        "\n",
        "    '''\n",
        "    Turn finetuning of the backbone layers on or off.\n",
        "    '''\n",
        "    def FTBackbone(backbone, boolVal):\n",
        "      for i, param in enumerate(backbone.parameters()):\n",
        "        param.requires_grad = boolVal\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTqusmWBE7_X"
      },
      "source": [
        "# Execute training and testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "naD0uVMUCF4e"
      },
      "outputs": [],
      "source": [
        "def evaluate(train_data, val_data, epochs, b_size, lr, momentum, weight_decay, optimizer_name, finetune_backbones):\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "    '''\n",
        "    Send to dataloader\n",
        "    '''\n",
        "    #Make use of dataloader so we can easily work with it later on.\n",
        "    train_loader = torch.utils.data.DataLoader(train_data,\n",
        "                                              batch_size=b_size,\n",
        "                                              shuffle=True,\n",
        "                                              drop_last = True)\n",
        "\n",
        "    val_loader = torch.utils.data.DataLoader(val_data,\n",
        "                                            batch_size=b_size,\n",
        "                                            shuffle=False,\n",
        "                                            drop_last = True)\n",
        "\n",
        "\n",
        "    '''\n",
        "    Initialize model, send to device and set optimizer\n",
        "    '''\n",
        "    model = Net(finetune_backbones).to(device)\n",
        "\n",
        "    #Optimizer\n",
        "    if optimizer_name == \"SGD\":\n",
        "      print(f'USING OPTIMIZER -------- SGD')\n",
        "      optimizer = torch.optim.SGD(model.parameters(),lr=lr, momentum= momentum, weight_decay= weight_decay)\n",
        "    else:\n",
        "      print(f'USING OPTIMIZER -------- ADAM')\n",
        "      optimizer = torch.optim.Adam(model.parameters(),lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "\n",
        "\n",
        "    '''\n",
        "    Train model for certain epochs\n",
        "    '''\n",
        "    for epoch in range(epochs):\n",
        "      train(model, device, train_loader, optimizer, epoch, display= True)# epoch%5==0)\n",
        "\n",
        "    '''\n",
        "    Test model and results (will run for each seed and store result so all seed accuracies can be aggregated)\n",
        "    '''\n",
        "    acc = test(model, device, val_loader)\n",
        "\n",
        "    #Average accuracies over all random state seeds\n",
        "    print('='*30)\n",
        "    print(f'Hyperparameters used were: \\n epochs, b_size, lr, momentum, weight_decay\\n {epochs}, {b_size}, {lr}, {momentum}, {weight_decay}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJvxpTSQ0SfC",
        "outputId": "438aea10-a05a-415f-a1a5-05014b387c40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:01<00:00, 73.2MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "USING OPTIMIZER -------- SGD\n",
            "Train Epoch: 0 [9984/10130 (99%)]\tLoss: 0.260191\n",
            "Train Epoch: 1 [9984/10130 (99%)]\tLoss: 0.245444\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.1803, Accuracy: 2343/2533 (92.50%)\n",
            "\n",
            "==============================\n",
            "Hyperparameters used were: \n",
            " epochs, b_size, lr, momentum, weight_decay\n",
            " 2, 128, 0.0001, 0, 0.0005\n"
          ]
        }
      ],
      "source": [
        "epochs = 2\n",
        "b_size = 128\n",
        "lr = 0.0001\n",
        "momentum = 0\n",
        "weight_decay = 0.0005\n",
        "optimizer_name = 'SGD'\n",
        "finetune_backbones = False\n",
        "\n",
        "evaluate(train_data, test_data, epochs, b_size, lr, momentum, weight_decay, optimizer_name, finetune_backbones)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "4bQxeevo4SXu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}