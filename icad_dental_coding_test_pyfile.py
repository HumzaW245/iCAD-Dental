# -*- coding: utf-8 -*-
"""iCAD Dental Coding Test.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Tq1ME6w7Z-CjI_vucUvapZzYJvIen9EB

# Downloading data using kaggle API

Read comment by 'Nikhil Ojha' for simple instructions on how to do download dataset (https://www.kaggle.com/discussions/general/74235)
"""

! pip install -q kaggle
from google.colab import files
files.upload() #Upload kaggle.json (it contains API key to access kaggle datasets)


from IPython.display import clear_output
clear_output() #To clear output printed since previous lines will show kaggle API key information

!rm -r ~/.kaggle
!mkdir ~/.kaggle
!mv ./kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json



# To download dataset, go to dataset ->https://www.kaggle.com/datasets/salviohexia/isic-2019-skin-lesion-images-for-classification/discussion
# Then click 3 dots menu -> 'Copy API Command'
# since in google colab, need to do ! first -> ! <pastedAPIcommandHere>

! kaggle datasets download -d salviohexia/isic-2019-skin-lesion-images-for-classification

import zipfile
zip_ref = zipfile.ZipFile('isic-2019-skin-lesion-images-for-classification.zip', 'r')
zip_ref.extractall('/content/ISIC2019')
zip_ref.close()

# ctrl-f 'In [13]' if want details of making a complete dataset using the metadata too -> https://www.kaggle.com/code/shonenkov/merge-external-data/notebook

import pandas as pd

# Specify the path to the CSV files
metadata_csv_file_path = '/content/ISIC2019/ISIC_2019_Training_Metadata.csv'
data_csv_file_path = '/content/ISIC2019/ISIC_2019_Training_GroundTruth.csv'



# Load the metadata and main data from the CSV file
metadata_df = pd.read_csv(metadata_csv_file_path)
main_df = pd.read_csv(data_csv_file_path)


#Getting class name and index column (index is used to make predictions more easily)
main_df['Class'] = main_df.apply(lambda row: main_df.columns[(row == 1)].tolist()[0], axis=1)
class_idx_map = {'MEL':0, 'NV':1, 'BCC':2, 'AK':3, 'BKL':4, 'DF':5, 'VASC':6, 'SCC':7, 'UNK':8}
main_df['Class_Index'] = main_df['Class'].apply(lambda class_name: class_idx_map[class_name])


print(main_df.head(-5))



dataset_dir = '/content/ISIC2019/'

import os
import pandas as pd
from PIL import Image
import numpy as np
import torch
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms

# Define a custom dataset class
class CustomDataset(Dataset):
    def __init__(self, root_dir, dataframe, transform=None):
        self.root_dir = root_dir
        self.dataframe = dataframe
        self.transform = transform

    def __len__(self):
        return len(self.dataframe)

    def __getitem__(self, idx):
        label = self.dataframe.iloc[idx]['Class_Index']
        class_name = self.dataframe.iloc[idx]['Class']
        #Get label index to tensor
        label = torch.tensor(label)

        #Get image
        img_id = self.dataframe.iloc[idx, 0]
        img_path = os.path.join(self.root_dir, class_name + '/' + img_id + '.jpg')  # Assuming images are in JPEG format
        image = Image.open(img_path).convert('RGB')

        #Apply transformations to image
        if self.transform:
            image = self.transform(image)

        return image, label

"""# DataLoaders and Transformations *************CHECK TRANSF THAT SHOULD BE APPLIED...maybe some standard one"""

import pandas as pd
import os
from sklearn.model_selection import train_test_split

# Split the data frame into training and test sets
train_df, test_df = train_test_split(main_df, test_size=0.2, random_state=42)


# Transformations to use for preprocessing (Arbitrarily chose these to have standardized data)
data_transforms = transforms.Compose([
    transforms.Resize((224, 224)),  # Resize the image to a common size
    transforms.ToTensor(),  # Convert PIL Image to PyTorch tensor
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize using ImageNet statistics
])

train_data = CustomDataset(dataset_dir, train_df, transform = data_transforms)
test_data = CustomDataset(dataset_dir, test_df, transform = data_transforms)



"""# Train and Test functions for how training will be done"""

import torch.nn.functional as F
def train(model, device, train_loader, optimizer, epoch, display=True):
    #Set model to training mode ----------------------------------CARE WHEN NORMALIZATION, DIFFERENT FOR TRAIN/TEST---------------------
    model.train()
    for batch_idx, (data, target) in enumerate(train_loader):

        #Data to device
        data, target = data.to(device), target.to(device)

        #Reset grad for next batch
        optimizer.zero_grad()
        output = model(data)

        #Loss
        loss = F.cross_entropy(output, target)

        #Backprop
        loss.backward()

        #Optimization step (Parameter Update)
        optimizer.step()


    #Log results of each epoch. CARE: Epoch will be an integer passed so the parameter is ONLY for tracking here. train(...) needs to be called in a loop based on how many epochs are to be trained (each epoch's index passed as epoch)
    if display:
      print('Train Epoch: {} [{}/{} ({:.0f}%)]\tLoss: {:.6f}'.format(
          epoch, batch_idx * len(data), len(train_loader.dataset),
          100. * batch_idx / len(train_loader), loss.item()))

def test(model, device, test_loader):
    #Set model to test mode ----------------------------------CARE WHEN NORMALIZATION, DIFFERENT FOR TRAIN/TEST---------------------
    model.eval()


    test_loss = 0
    correct = 0

    #no_grad() will not hold grad, which is fine since we do not want to calculate gradient as we are only interested in checking the prediction from the forward pass.
    with torch.no_grad():
        for data, target in test_loader:
            data, target = data.to(device), target.to(device)
            output = model(data)

            #Test Loss
            test_loss += F.cross_entropy(output, target, size_average=False).item() # sum up batch loss

            #Predicted class
            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability

            #Number of correct predictions in the batch to update overall total of correct predictions
            correct += pred.eq(target.view_as(pred)).sum().item()

    #Average test loss over all dataset
    test_loss /= len(test_loader.dataset)

    #Log results
    print('\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\n'.format(
        test_loss, correct, len(test_loader.dataset),
        100. * correct / len(test_loader.dataset)))

    #Return Accuracy Percent
    return 100. * correct / len(test_loader.dataset)

"""# Define the Network"""

import torch
import torch.nn as nn
import torch.nn.functional as F

import torchvision.models as models

class Net(torch.nn.Module):
    '''
    Constructor. Define all layers (These were chosen through trying different variations by starting with 2-3 convolution layers and adding batchNorm and pooling between them as needed, with different parameters)
    '''
    def __init__(self, finetune_backbones):
        super(Net, self).__init__()
        self.model =  models.resnet50(pretrained=True)

        # FT backbone (before output layers. freeze/unfreeze)
        self.finetune_backbones = finetune_backbones
        for i, param in enumerate(self.model.parameters()):
          param.requires_grad = self.finetune_backbones


        #New output head for the target task
        in_features = self.model.fc.in_features #The fc layer of resenet50 is Linear(in_features=2048, out_features=1000, bias=True) so storing the 2048 and replacing this to map from 2048 to numClasses for target task ====can see the fc layer like this: backbone = models.resnet50(pretrained=True) => print(backbone.fc)
        targetTaskOutFeatures = 9 # num of classes in target task
        classifier = nn.Linear(in_features, targetTaskOutFeatures, bias=True)  # Create a new classifier
        classifier.weight.requires_grad = True
        classifier.bias.requires_grad = True
        self.model.fc = classifier  # Replace the classifier layer

        # self.layers = nn.ModuleList()

        # # 3 Channels in (RGB at the start is what image channels are) and 16 channels out (arbitrarily chose 16)
        # self.layers+=[nn.Conv2d(3, 16,  kernel_size=3) ,
        #               nn.ReLU(inplace=True)]

        # # Batch norm layer to normalize the tensor produced from convolution so covariances are not too high and this can help avoid issues like oscillating loss
        # self.layers+=[nn.BatchNorm2d(16)]

        # # Pooling to reduce number of params to learn so training time is improved by reducing dimension (e.g. image size) as it passes through the Net
        # # basically as if multiple pixels would share the same parameter so 1 gradient is calculated between multiple pixels to allow training without needing higher number of computations (less gradients to calculate)
        # self.layers+=[nn.MaxPool2d(kernel_size= 2, stride=2, padding= 0)]

        # self.layers+=[nn.Conv2d(16, 32,  kernel_size=3),
        #               nn.ReLU(inplace=True)]

        # self.layers+=[nn.MaxPool2d(kernel_size= 2, stride=2, padding= 0)]

        # self.layers+=[nn.Conv2d(32, 32,  kernel_size=3),
        #               nn.ReLU(inplace=True)]

        # self.layers+=[nn.MaxPool2d(kernel_size= 2, stride=2, padding= 0)]


        # '''
        # Linear layers after flattening
        # # '''
        # self.fc1 = nn.Linear(32*26*26, 64) #NEED TO MODIFY first argument to output of previous layers' size product of each observation. THIS BASED ON LAST INPUT SIZE (Changes as we do convolutions, pooling, etc)
        # self.layer_norm1 = nn.LayerNorm(64)
        # self.fc2 = nn.Linear(64, 30)
        # self.layer_norm2 = nn.LayerNorm(30)
        # self.fc3 = nn.Linear(30, 9) # Linear layer from X neurons to Y where y is number of classes being predicted
    '''
    Forward Pass
    '''
    def forward(self, x):

        x = self.model(x)
        return x
        # for i in range(len(self.layers)):
        #   #print(f'Input size before layer: {self.layers[i]} --- size: {x.shape}')
        #   x = self.layers[i](x)

        #print(f'Input size before flattening convolution layers result -> {x.shape}')
        # outChannelsHeightWidthproduct = x.shape[1]*x.shape[2]*x.shape[3]
        # x = x.view(-1, outChannelsHeightWidthproduct)


        # x = nn.functional.relu(self.fc1(x))


        # x = self.layer_norm1(x)
        # x = nn.functional.relu(self.fc2(x))
        # x = self.layer_norm2(x)
        # x = self.fc3(x)
        #print(f'Final input size -> {x.shape}')
        #return x


    '''
    Turn finetuning of the backbone layers on or off.
    '''
    def FTBackbone(backbone, boolVal):
      for i, param in enumerate(backbone.parameters()):
        param.requires_grad = boolVal

"""# Execute training and testing"""

def evaluate(train_data, val_data, epochs, b_size, lr, momentum, weight_decay, optimizer_name, finetune_backbones):
    device = 'cuda'
    '''
    Send to dataloader
    '''
    #Make use of dataloader so we can easily work with it later on.
    train_loader = torch.utils.data.DataLoader(train_data,
                                              batch_size=b_size,
                                              shuffle=True,
                                              drop_last = True)

    val_loader = torch.utils.data.DataLoader(val_data,
                                            batch_size=b_size,
                                            shuffle=False,
                                            drop_last = True)


    '''
    Initialize model, send to device and set optimizer
    '''
    model = Net(finetune_backbones).to(device)

    #Optimizer
    if optimizer_name == "SGD":
      print(f'USING OPTIMIZER -------- SGD')
      optimizer = torch.optim.SGD(model.parameters(),lr=lr, momentum= momentum, weight_decay= weight_decay)
    else:
      print(f'USING OPTIMIZER -------- ADAM')
      optimizer = torch.optim.Adam(model.parameters(),lr=lr, weight_decay=weight_decay)



    '''
    Train model for certain epochs
    '''
    for epoch in range(epochs):
      train(model, device, train_loader, optimizer, epoch, display= True)# epoch%5==0)

    '''
    Test model and results (will run for each seed and store result so all seed accuracies can be aggregated)
    '''
    acc = test(model, device, val_loader)

    #Average accuracies over all random state seeds
    print('='*30)
    print(f'Hyperparameters used were: \n epochs, b_size, lr, momentum, weight_decay\n {epochs}, {b_size}, {lr}, {momentum}, {weight_decay}')

epochs = 20
b_size = 32
lr = 0.0001
momentum = 0
weight_decay = 0.0005
optimizer_name = 'SGD'
finetune_backbones = False

evaluate(train_data, test_data, epochs, b_size, lr, momentum, weight_decay, optimizer_name, finetune_backbones)

